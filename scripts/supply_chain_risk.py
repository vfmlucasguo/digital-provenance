#!/usr/bin/env python3
"""
ä¾›åº”é“¾é£é™©è¯„ä¼°è„šæœ¬
è¯„ä¼°SBOMä¸­ç»„ä»¶çš„ä¾›åº”é“¾å®‰å…¨é£é™©
"""

import json
import sys
import re
from datetime import datetime, timedelta
from typing import Dict, List, Set, Optional

# é£é™©è¯„ä¼°è§„åˆ™
RISK_RULES = {
    'age_risk': {
        'very_old': 365 * 3,  # 3å¹´ä»¥ä¸Š
        'old': 365 * 2,       # 2å¹´ä»¥ä¸Š
        'outdated': 365       # 1å¹´ä»¥ä¸Š
    },
    'maintenance_risk': {
        'abandoned_threshold': 365 * 2,  # 2å¹´æœªæ›´æ–°
        'low_maintenance': 365           # 1å¹´æœªæ›´æ–°
    },
    'popularity_risk': {
        'unknown_package': True,
        'low_download_threshold': 1000
    }
}

# é«˜é£é™©åŒ…åæ¨¡å¼
HIGH_RISK_PATTERNS = [
    r'.*-dev$',           # å¼€å‘ç‰ˆæœ¬
    r'.*-beta$',          # æµ‹è¯•ç‰ˆæœ¬
    r'.*-alpha$',         # æ—©æœŸç‰ˆæœ¬
    r'.*-rc\d*$',         # å€™é€‰ç‰ˆæœ¬
    r'.*-snapshot$',      # å¿«ç…§ç‰ˆæœ¬
    r'^test-.*',          # æµ‹è¯•åŒ…
    r'^demo-.*',          # æ¼”ç¤ºåŒ…
]

# å¯ä¿¡å‘å¸ƒè€…/ç»„ç»‡
TRUSTED_PUBLISHERS = {
    'npm': {
        'facebook', 'google', 'microsoft', 'angular', 'react',
        'typescript', 'webpack', 'babel', 'eslint', 'prettier'
    },
    'pypi': {
        'python', 'django', 'flask', 'requests', 'numpy', 'pandas'
    }
}

def load_sbom(file_path: str) -> Dict:
    """åŠ è½½SBOMæ–‡ä»¶"""
    try:
        with open(file_path, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
        sys.exit(1)
    except json.JSONDecodeError:
        print(f"âŒ é”™è¯¯: æ— æ•ˆçš„JSONæ–‡ä»¶ {file_path}")
        sys.exit(1)

def parse_version(version_str: str) -> Dict:
    """è§£æç‰ˆæœ¬ä¿¡æ¯"""
    if not version_str:
        return {'major': 0, 'minor': 0, 'patch': 0, 'prerelease': True}

    # ç§»é™¤å‰ç¼€ (å¦‚ v1.0.0 -> 1.0.0)
    version_str = re.sub(r'^v', '', version_str)

    # æ£€æŸ¥æ˜¯å¦ä¸ºé¢„å‘å¸ƒç‰ˆæœ¬
    prerelease = bool(re.search(r'-(alpha|beta|rc|dev|snapshot)', version_str, re.I))

    # æå–æ•°å­—ç‰ˆæœ¬
    match = re.match(r'(\d+)(?:\.(\d+))?(?:\.(\d+))?', version_str)
    if match:
        major = int(match.group(1) or 0)
        minor = int(match.group(2) or 0)
        patch = int(match.group(3) or 0)
    else:
        major = minor = patch = 0

    return {
        'major': major,
        'minor': minor,
        'patch': patch,
        'prerelease': prerelease,
        'original': version_str
    }

def assess_version_risk(component: Dict) -> Dict:
    """è¯„ä¼°ç‰ˆæœ¬é£é™©"""
    risks = []
    version_info = parse_version(component.get('version', ''))

    # é¢„å‘å¸ƒç‰ˆæœ¬é£é™©
    if version_info['prerelease']:
        risks.append({
            'type': 'prerelease_version',
            'severity': 'MEDIUM',
            'description': 'ä½¿ç”¨é¢„å‘å¸ƒç‰ˆæœ¬ï¼Œå¯èƒ½ä¸ç¨³å®š'
        })

    # ç‰ˆæœ¬å·é£é™©æ¨¡å¼
    version_str = component.get('version', '')
    for pattern in HIGH_RISK_PATTERNS:
        if re.match(pattern, version_str, re.I):
            risks.append({
                'type': 'risky_version_pattern',
                'severity': 'MEDIUM',
                'description': f'ç‰ˆæœ¬å·åŒ¹é…é«˜é£é™©æ¨¡å¼: {pattern}'
            })

    # ä¸»ç‰ˆæœ¬å·ä¸º0çš„é£é™©
    if version_info['major'] == 0:
        risks.append({
            'type': 'zero_major_version',
            'severity': 'LOW',
            'description': 'ä¸»ç‰ˆæœ¬å·ä¸º0ï¼ŒAPIå¯èƒ½ä¸ç¨³å®š'
        })

    return risks

def assess_naming_risk(component: Dict) -> List[Dict]:
    """è¯„ä¼°å‘½åé£é™©"""
    risks = []
    name = component.get('name', '').lower()

    # æ£€æŸ¥å¯ç–‘çš„åŒ…å
    suspicious_patterns = [
        (r'.*password.*', 'åŒ…ååŒ…å«æ•æ„Ÿè¯æ±‡'),
        (r'.*secret.*', 'åŒ…ååŒ…å«æ•æ„Ÿè¯æ±‡'),
        (r'.*token.*', 'åŒ…ååŒ…å«æ•æ„Ÿè¯æ±‡'),
        (r'.*hack.*', 'åŒ…ååŒ…å«å¯ç–‘è¯æ±‡'),
        (r'.*crack.*', 'åŒ…ååŒ…å«å¯ç–‘è¯æ±‡'),
        (r'.*exploit.*', 'åŒ…ååŒ…å«å¯ç–‘è¯æ±‡'),
    ]

    for pattern, description in suspicious_patterns:
        if re.search(pattern, name):
            risks.append({
                'type': 'suspicious_naming',
                'severity': 'MEDIUM',
                'description': description
            })

    # æ£€æŸ¥å•å­—ç¬¦æˆ–æçŸ­åŒ…å
    if len(name) <= 2:
        risks.append({
            'type': 'short_name',
            'severity': 'LOW',
            'description': 'åŒ…åè¿‡çŸ­ï¼Œå¯èƒ½æ˜¯å ä½åŒ…'
        })

    # æ£€æŸ¥åŒ…å«æ•°å­—çš„å¥‡æ€ªæ¨¡å¼
    if re.search(r'\d{4,}', name):  # åŒ…å«4ä½ä»¥ä¸Šæ•°å­—
        risks.append({
            'type': 'numeric_pattern',
            'severity': 'LOW',
            'description': 'åŒ…ååŒ…å«é•¿æ•°å­—åºåˆ—ï¼Œå¯èƒ½æ˜¯è‡ªåŠ¨ç”Ÿæˆ'
        })

    return risks

def assess_dependency_risk(components: List[Dict]) -> Dict:
    """è¯„ä¼°ä¾èµ–å…³ç³»é£é™©"""
    risks = []

    # ç»Ÿè®¡ä¾èµ–æ·±åº¦å’Œå¹¿åº¦
    total_deps = len(components)
    direct_deps = len([c for c in components if c.get('scope') == 'required'])

    # ä¾èµ–è¿‡å¤šé£é™©
    if total_deps > 500:
        risks.append({
            'type': 'excessive_dependencies',
            'severity': 'HIGH',
            'description': f'ä¾èµ–æ•°é‡è¿‡å¤š ({total_deps}ä¸ª)ï¼Œå¢åŠ ä¾›åº”é“¾æ”»å‡»é¢'
        })
    elif total_deps > 200:
        risks.append({
            'type': 'many_dependencies',
            'severity': 'MEDIUM',
            'description': f'ä¾èµ–æ•°é‡è¾ƒå¤š ({total_deps}ä¸ª)ï¼Œéœ€è¦å…³æ³¨'
        })

    # åˆ†æä¾èµ–æ¥æºå¤šæ ·æ€§
    publishers = set()
    for comp in components:
        # å°è¯•ä»åŒ…åæ¨æ–­å‘å¸ƒè€…
        name = comp.get('name', '')
        if '/' in name:  # scoped package like @angular/core
            publisher = name.split('/')[0].lstrip('@')
            publishers.add(publisher)

    if len(publishers) > 50:
        risks.append({
            'type': 'diverse_publishers',
            'severity': 'MEDIUM',
            'description': f'ä¾èµ–æ¥è‡ª {len(publishers)} ä¸ªä¸åŒå‘å¸ƒè€…ï¼Œå¢åŠ é£é™©'
        })

    return {
        'risks': risks,
        'statistics': {
            'total_dependencies': total_deps,
            'direct_dependencies': direct_deps,
            'unique_publishers': len(publishers)
        }
    }

def assess_component_risk(component: Dict) -> Dict:
    """è¯„ä¼°å•ä¸ªç»„ä»¶çš„é£é™©"""
    risks = []
    name = component.get('name', '')
    version = component.get('version', '')

    # ç‰ˆæœ¬é£é™©
    risks.extend(assess_version_risk(component))

    # å‘½åé£é™©
    risks.extend(assess_naming_risk(component))

    # è®¡ç®—æ€»ä½“é£é™©ç­‰çº§
    risk_scores = {'CRITICAL': 4, 'HIGH': 3, 'MEDIUM': 2, 'LOW': 1}
    total_score = sum(risk_scores.get(risk['severity'], 0) for risk in risks)

    if total_score >= 6:
        overall_risk = 'HIGH'
    elif total_score >= 3:
        overall_risk = 'MEDIUM'
    elif total_score > 0:
        overall_risk = 'LOW'
    else:
        overall_risk = 'MINIMAL'

    return {
        'component': name,
        'version': version,
        'risks': risks,
        'overall_risk': overall_risk,
        'risk_score': total_score
    }

def generate_risk_report(component_risks: List[Dict], dependency_analysis: Dict) -> str:
    """ç”Ÿæˆé£é™©è¯„ä¼°æŠ¥å‘Š"""
    report = "# ğŸ” ä¾›åº”é“¾é£é™©è¯„ä¼°æŠ¥å‘Š\n\n"

    # æ€»ä½“ç»Ÿè®¡
    total_components = len(component_risks)
    high_risk = len([c for c in component_risks if c['overall_risk'] == 'HIGH'])
    medium_risk = len([c for c in component_risks if c['overall_risk'] == 'MEDIUM'])
    low_risk = len([c for c in component_risks if c['overall_risk'] == 'LOW'])

    report += f"## ğŸ“Š é£é™©æ¦‚è§ˆ\n\n"
    report += f"- æ€»ç»„ä»¶æ•°: {total_components}\n"
    report += f"- ğŸ”´ é«˜é£é™©: {high_risk} ä¸ª\n"
    report += f"- ğŸŸ¡ ä¸­é£é™©: {medium_risk} ä¸ª\n"
    report += f"- ğŸŸ¢ ä½é£é™©: {low_risk} ä¸ª\n"
    report += f"- âšª æœ€å°é£é™©: {total_components - high_risk - medium_risk - low_risk} ä¸ª\n\n"

    # ä¾èµ–å…³ç³»åˆ†æ
    dep_stats = dependency_analysis['statistics']
    report += f"## ğŸ“ˆ ä¾èµ–å…³ç³»åˆ†æ\n\n"
    report += f"- æ€»ä¾èµ–æ•°: {dep_stats['total_dependencies']}\n"
    report += f"- ç›´æ¥ä¾èµ–: {dep_stats['direct_dependencies']}\n"
    report += f"- å‘å¸ƒè€…æ•°é‡: {dep_stats['unique_publishers']}\n\n"

    # ä¾èµ–é£é™©
    if dependency_analysis['risks']:
        report += f"### âš ï¸ ä¾èµ–ç»“æ„é£é™©\n\n"
        for risk in dependency_analysis['risks']:
            report += f"- **{risk['severity']}**: {risk['description']}\n"
        report += "\n"

    # é«˜é£é™©ç»„ä»¶è¯¦æƒ…
    high_risk_components = [c for c in component_risks if c['overall_risk'] == 'HIGH']
    if high_risk_components:
        report += f"## ğŸ”´ é«˜é£é™©ç»„ä»¶ ({len(high_risk_components)}ä¸ª)\n\n"
        for comp in high_risk_components[:10]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
            report += f"### {comp['component']}@{comp['version']}\n\n"
            report += f"**é£é™©è¯„åˆ†**: {comp['risk_score']}\n\n"
            report += "**é£é™©è¯¦æƒ…**:\n"
            for risk in comp['risks']:
                report += f"- **{risk['severity']}**: {risk['description']}\n"
            report += "\n"

    # é£é™©ç±»å‹ç»Ÿè®¡
    risk_types = {}
    for comp in component_risks:
        for risk in comp['risks']:
            risk_type = risk['type']
            if risk_type not in risk_types:
                risk_types[risk_type] = 0
            risk_types[risk_type] += 1

    if risk_types:
        report += f"## ğŸ“‹ é£é™©ç±»å‹ç»Ÿè®¡\n\n"
        sorted_risks = sorted(risk_types.items(), key=lambda x: x[1], reverse=True)
        for risk_type, count in sorted_risks:
            report += f"- {risk_type}: {count} æ¬¡\n"
        report += "\n"

    # å»ºè®®
    report += f"## ğŸ’¡ æ”¹è¿›å»ºè®®\n\n"
    if high_risk_components:
        report += "1. **ç«‹å³å¤„ç†é«˜é£é™©ç»„ä»¶**: è€ƒè™‘æ›¿æ¢æˆ–å‡çº§é«˜é£é™©ä¾èµ–\n"
    if medium_risk > total_components * 0.3:
        report += "2. **å®¡æŸ¥ä¸­é£é™©ç»„ä»¶**: è¯„ä¼°æ˜¯å¦æœ‰æ›´å®‰å…¨çš„æ›¿ä»£æ–¹æ¡ˆ\n"
    if dep_stats['total_dependencies'] > 300:
        report += "3. **å‡å°‘ä¾èµ–æ•°é‡**: è€ƒè™‘ç§»é™¤ä¸å¿…è¦çš„ä¾èµ–\n"
    report += "4. **å®šæœŸæ›´æ–°**: å»ºç«‹å®šæœŸæ›´æ–°ä¾èµ–çš„æµç¨‹\n"
    report += "5. **ç›‘æ§æ–°æ¼æ´**: è®¢é˜…å®‰å…¨å…¬å‘Šï¼ŒåŠæ—¶å“åº”æ–°å‘ç°çš„æ¼æ´\n\n"

    return report

def main():
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python3 supply_chain_risk.py <sbom_file.json>")
        sys.exit(1)

    sbom_file = sys.argv[1]
    print(f"ğŸ” æ­£åœ¨è¯„ä¼°ä¾›åº”é“¾é£é™©: {sbom_file}")

    # åŠ è½½SBOM
    sbom = load_sbom(sbom_file)
    components = sbom.get('components', [])

    print(f"ğŸ“¦ åˆ†æ {len(components)} ä¸ªç»„ä»¶çš„ä¾›åº”é“¾é£é™©...")

    # è¯„ä¼°æ¯ä¸ªç»„ä»¶çš„é£é™©
    component_risks = []
    for component in components:
        risk_assessment = assess_component_risk(component)
        component_risks.append(risk_assessment)

    # è¯„ä¼°ä¾èµ–å…³ç³»é£é™©
    dependency_analysis = assess_dependency_risk(components)

    # ç”ŸæˆæŠ¥å‘Š
    report = generate_risk_report(component_risks, dependency_analysis)
    print(report)

    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
    with open('supply-chain-risk-report.md', 'w') as f:
        f.write(report)
    print("ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: supply-chain-risk-report.md")

    # æ ¹æ®é£é™©ç­‰çº§å†³å®šé€€å‡ºç 
    high_risk_count = len([c for c in component_risks if c['overall_risk'] == 'HIGH'])
    critical_dependency_risks = len([r for r in dependency_analysis['risks']
                                   if r['severity'] in ['CRITICAL', 'HIGH']])

    if high_risk_count > 5 or critical_dependency_risks > 0:
        print(f"\nâš ï¸ å‘ç° {high_risk_count} ä¸ªé«˜é£é™©ç»„ä»¶å’Œ {critical_dependency_risks} ä¸ªä¸¥é‡ä¾èµ–é£é™©")
        print("å»ºè®®åœ¨éƒ¨ç½²å‰è§£å†³è¿™äº›é£é™©")
        # å¯ä»¥æ ¹æ®æ”¿ç­–å†³å®šæ˜¯å¦å¤±è´¥æ„å»º
        # sys.exit(1)

    print("âœ… ä¾›åº”é“¾é£é™©è¯„ä¼°å®Œæˆ")

if __name__ == "__main__":
    main()