"""
AIBOM å…¨é‡ç»Ÿè®¡è„šæœ¬ï¼šæ”¯æŒæ•´æ–‡ä»¶ + éƒ¨åˆ†ä»£ç ç‰‡æ®µ + å½“å‰æäº¤ç»Ÿè®¡

## æ”¯æŒçš„æ ‡æ³¨æ–¹å¼

1. **æ•´æ–‡ä»¶ - è·¯å¾„**: è·¯å¾„å« `ai-gen` â†’ æ•´ä¸ªæ–‡ä»¶è®¡ä¸º AI
2. **æ•´æ–‡ä»¶ - å¤´éƒ¨**: å‰ 10 è¡Œå†…ä»»ä¸€è¡Œå« `@ai-generated` æˆ– `@generated-ai` â†’ æ•´ä¸ªæ–‡ä»¶
3. **éƒ¨åˆ† - å—å¼€å§‹/ç»“æŸ**:
   - `// @ai-generated-begin` ... `// @ai-generated-end` ä¹‹é—´çš„è¡Œ
4. **éƒ¨åˆ† - ç‹¬ç«‹æ³¨é‡Šå—**: `// @ai-generated` å•ç‹¬ä¸€è¡Œ â†’ æ ‡è®°ä¸‹ä¸€å—ï¼ˆåˆ°ç¼©è¿›å›é€€ï¼‰
5. **éƒ¨åˆ† - è¡Œå°¾/è¡Œå†…**: æŸè¡Œå« `@ai-generated` â†’ è¯¥è¡Œè®¡ä¸º AI

## ç»Ÿè®¡ç»´åº¦
- **é¡¹ç›®ç´¯è®¡**: æ‰«æ src/ å…¨é‡ï¼Œç»Ÿè®¡æ€» AI æ¸—é€ç‡
- **å½“å‰æäº¤**: ä»…ç»Ÿè®¡æœ¬ commit diff ä¸­æ–°å¢ä¸”ä¸º AI çš„è¡Œï¼ˆéœ€ --commitï¼‰

## ç”¨æ³•
  python3 scripts/process_aibom.py              # é¡¹ç›®ç´¯è®¡
  python3 scripts/process_aibom.py --commit     # å«å½“å‰æäº¤ç»Ÿè®¡ï¼ˆé»˜è®¤ base=HEAD~1ï¼‰
  python3 scripts/process_aibom.py --commit --base origin/main
  python3 scripts/process_aibom.py --append-history
"""
import argparse
import json
import os
import re
import subprocess
from datetime import datetime
from pathlib import Path

# æ”¯æŒçš„æ–‡ä»¶ç±»å‹
SRC_EXTENSIONS = ('.ts', '.tsx', '.html', '.htm', '.scss', '.css', '.js', '.jsx', '.vue')
# å¤´éƒ¨åˆ¤å®šè¡Œæ•°
HEADER_LINES = 10
# AI æ ‡è®°å…³é”®å­—ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
AI_MARKERS = ('@ai-generated', '@ai-generated-begin', '@ai-generated-end', '@generated-ai')


def _get_base_indent(line: str) -> int:
    return len(line) - len(line.lstrip())


def _count_non_empty(lines: list[str]) -> int:
    return sum(1 for l in lines if l.strip())


def analyze_file(file_path: str, project_root: str = ".") -> dict:
    """
    åˆ†æå•ä¸ªæ–‡ä»¶ï¼Œè¿”å›æ•´æ–‡ä»¶/éƒ¨åˆ†ç‰‡æ®µçš„ AI ç»Ÿè®¡
    æ”¯æŒ: è·¯å¾„(ai-gen)ã€å¤´éƒ¨(@ai-generated)ã€è¡Œå°¾ã€å—(@ai-generated-begin/end)
    """
    full_path = os.path.join(project_root, file_path)
    result = {
        "total_lines": 0,
        "whole_file": False,
        "partial_lines": 0,
        "ai_lines": 0,
        "scope": "none",
        "details": []
    }
    try:
        with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
    except Exception:
        return result

    total = _count_non_empty(lines)
    result["total_lines"] = total
    result["ai_line_indices"] = set()
    if total == 0:
        return result

    def _all_non_empty_indices():
        return set(i for i, ln in enumerate(lines) if ln.strip())

    # 1. æ•´æ–‡ä»¶ï¼šè·¯å¾„å« ai-gen
    if 'ai-gen' in file_path.lower():
        result["whole_file"] = True
        result["ai_lines"] = total
        result["scope"] = "whole"
        result["ai_line_indices"] = _all_non_empty_indices()
        return result

    # 2. æ•´æ–‡ä»¶ï¼šå¤´éƒ¨(å‰ N è¡Œ) æœ‰ @ai-generated æˆ– @generated-ai
    for line in lines[:HEADER_LINES]:
        sl = line.strip().lower()
        if '@ai-generated' in sl or '@generated-ai' in sl:
            if '@ai-generated-end' not in sl:
                result["whole_file"] = True
                result["ai_lines"] = total
                result["scope"] = "whole"
                result["ai_line_indices"] = _all_non_empty_indices()
                return result

    # 3. éƒ¨åˆ†ç‰‡æ®µï¼šè¡Œçº§ + å—çº§æ ‡è®°
    ai_line_indices = set()
    in_block = False
    block_indent = -1

    i = 0
    while i < len(lines):
        line = lines[i]
        stripped = line.strip()
        s_lower = stripped.lower()
        indent = _get_base_indent(line)

        if not stripped:
            i += 1
            continue

        # å—ç»“æŸ
        if '@ai-generated-end' in s_lower:
            in_block = False
            block_indent = -1
            i += 1
            continue

        # å—å¼€å§‹
        if '@ai-generated-begin' in s_lower:
            in_block = True
            block_indent = indent
            i += 1
            continue

        if in_block:
            if indent <= block_indent and block_indent >= 0:
                in_block = False
            else:
                ai_line_indices.add(i)
            i += 1
            continue

        # çº¯æ³¨é‡Šè¡Œä¸Šçš„ standalone æ ‡è®°ï¼šæ ‡è®°ã€Œä¸‹ä¸€å—ã€åˆ°ç¼©è¿›å›é€€
        is_comment = (
            s_lower.startswith('//') or s_lower.startswith('#') or
            s_lower.startswith('*') or s_lower.startswith('<!--')
        )
        if is_comment and ('@ai-generated' in s_lower or '@generated-ai' in s_lower):
            if '@ai-generated-end' in s_lower or '@ai-generated-begin' in s_lower:
                i += 1
                continue
            # æ ‡è®°ä¸‹ä¸€å—ï¼šä»ä¸‹ä¸€éç©ºè¡Œèµ·ï¼Œç›´åˆ°ç¼©è¿›ä¸¥æ ¼å°äºæ³¨é‡Šè¡Œ
            j = i + 1
            while j < len(lines):
                nl = lines[j]
                ns = nl.strip()
                ni = _get_base_indent(lines[j])
                if not ns:
                    j += 1
                    continue
                if ni < indent:
                    break
                if '@ai-generated' in ns.lower() or '@ai-generated-begin' in ns.lower():
                    break
                ai_line_indices.add(j)
                j += 1
            i += 1
            continue

        # è¡Œå°¾/è¡Œå†…æ ‡è®°ï¼šè¯¥è¡Œå« @ai-generated
        if ('@ai-generated' in s_lower or '@generated-ai' in s_lower) and '@ai-generated-end' not in s_lower:
            ai_line_indices.add(i)

        i += 1

    result["partial_lines"] = len(ai_line_indices)
    result["ai_lines"] = len(ai_line_indices)
    result["ai_line_indices"] = ai_line_indices
    if result["ai_lines"] > 0:
        result["scope"] = "partial"
    return result


def _run_git(cmd, cwd="."):
    try:
        r = subprocess.run(cmd, cwd=cwd, capture_output=True, text=True, timeout=30)
        return r.stdout.strip() if r.returncode == 0 else ""
    except Exception:
        return ""


def get_changed_src_files(base, head, project_root):
    """è·å– base..head ä¹‹é—´å˜æ›´çš„ src/ ä¸‹æºæ–‡ä»¶è·¯å¾„"""
    out = _run_git(["git", "diff", "--name-only", base, head], cwd=project_root)
    if not out:
        return []
    result = []
    for line in out.splitlines():
        p = line.strip()
        if p and p.startswith("src/") and any(p.lower().endswith(ext) for ext in SRC_EXTENSIONS):
            result.append(p.replace("\\", "/"))
    return sorted(set(result))


def get_diff_added_line_numbers(base, head, filepath, project_root):
    """è§£æ git diffï¼Œè¿”å› filepath åœ¨ head ç‰ˆæœ¬ä¸­ã€Œæ–°å¢è¡Œã€çš„ 0-based è¡Œå·é›†åˆ"""
    out = _run_git(["git", "diff", "-U0", base, head, "--", filepath], cwd=project_root)
    if not out:
        return set()
    added = set()
    hunk_re = re.compile(r"^@@ -[\d,]+ \+(\d+)(?:,(\d+))? @@")
    new_line = 0
    in_hunk = False
    for raw in out.splitlines():
        if raw.startswith("@@"):
            m = hunk_re.match(raw)
            if m:
                new_line = int(m.group(1)) - 1
                in_hunk = True
            continue
        if not in_hunk:
            continue
        if raw.startswith("+"):
            if raw.startswith("+++"):
                continue
            added.add(new_line)
            new_line += 1
        elif not raw.startswith("---"):
            new_line += 1
    return added


def compute_commit_stats(base, head, project_root, file_results):
    """è®¡ç®—å½“å‰æäº¤çš„ AI ç»Ÿè®¡ï¼šä»…ç»Ÿè®¡ diff æ–°å¢è¡Œä¸­å±äº AI åŒºåŸŸçš„è¡Œ"""
    changed = get_changed_src_files(base, head, project_root)
    if not changed:
        return {"ai_lines": 0, "total_added": 0, "changed_files": 0, "ai_changed_files": 0}
    commit_ai = 0
    commit_total = 0
    ai_file_count = 0
    for fp in changed:
        added = get_diff_added_line_numbers(base, head, fp, project_root)
        if not added:
            continue
        commit_total += len(added)
        r = file_results.get(fp)
        if not r:
            r = analyze_file(fp, project_root)
        overlap = added & r.get("ai_line_indices", set())
        if overlap:
            commit_ai += len(overlap)
            ai_file_count += 1
    return {
        "ai_lines": commit_ai,
        "total_added": commit_total,
        "changed_files": len(changed),
        "ai_changed_files": ai_file_count,
    }


def collect_src_files(project_root: str, src_dir: str = "src") -> list:
    """é€’å½’æ”¶é›† src ä¸‹æ‰€æœ‰æ”¯æŒçš„æºæ–‡ä»¶"""
    base = os.path.join(project_root, src_dir)
    if not os.path.isdir(base):
        return []
    files = []
    for root, _, names in os.walk(base):
        for name in names:
            if name.lower().endswith(SRC_EXTENSIONS):
                full = os.path.join(root, name)
                rel = os.path.relpath(full, project_root)
                files.append(rel.replace("\\", "/"))
    return sorted(files)


def process(args=None):
    input_path = "base-sbom.json"
    output_path = "aibom-final.json"
    project_root = "."
    opts = args or argparse.Namespace(commit=False, base="HEAD~1", append_history=False)

    # 1. ç›´æ¥æ‰«æ src/ è·å–å…¨é‡æ–‡ä»¶ï¼ˆä¸ä¾èµ– BOMï¼‰
    src_files = collect_src_files(project_root)
    file_results = {}
    total_lines = 0
    ai_whole_lines = 0
    ai_partial_lines = 0
    whole_files_count = 0
    partial_files_count = 0

    for fp in src_files:
        r = analyze_file(fp, project_root)
        file_results[fp] = r
        total_lines += r["total_lines"]
        if r["scope"] == "whole":
            ai_whole_lines += r["ai_lines"]
            whole_files_count += 1
        elif r["scope"] == "partial":
            ai_partial_lines += r["partial_lines"]
            partial_files_count += 1

    ai_total_lines = ai_whole_lines + ai_partial_lines

    # 1b. å½“å‰æäº¤ç»Ÿè®¡ï¼ˆå¯é€‰ï¼‰
    commit_stats = None
    git_commit = ""
    git_commit_short = ""
    if opts.commit:
        git_commit = _run_git(["git", "rev-parse", "HEAD"], project_root)
        git_commit_short = _run_git(["git", "rev-parse", "--short", "HEAD"], project_root)
        commit_stats = compute_commit_stats(opts.base, "HEAD", project_root, file_results)

    # 2. åŠ è½½ BOM å¹¶æ›´æ–°åŒ¹é…çš„ç»„ä»¶
    bom = {"metadata": {"properties": []}, "components": []}
    if os.path.exists(input_path):
        with open(input_path, 'r', encoding='utf-8') as f:
            bom = json.load(f)

    def set_prop(props: list, name: str, value: str):
        for p in props:
            if p.get("name") == name:
                p["value"] = value
                return
        props.append({"name": name, "value": value})

    for fp, r in file_results.items():
        if r["scope"] in ("whole", "partial"):
            matched = False
            for comp in bom.get("components", []):
                cname = comp.get("name", "")
                if fp in cname or cname.endswith(fp) or os.path.normpath(fp) in os.path.normpath(cname):
                    props = comp.setdefault("properties", [])
                    set_prop(props, "ai:generated", "true")
                    set_prop(props, "ai:scope", r["scope"])
                    set_prop(props, "ai:lines", str(r["ai_lines"]))
                    matched = True
            if not matched and bom.get("components") is not None:
                # BOM ä¸­å¯èƒ½æ— è¯¥æ–‡ä»¶ï¼Œæ³¨å…¥ä¸º file ç»„ä»¶
                bom["components"].append({
                    "type": "file",
                    "name": fp,
                    "properties": [
                        {"name": "ai:generated", "value": "true"},
                        {"name": "ai:scope", "value": r["scope"]},
                        {"name": "ai:lines", "value": str(r["ai_lines"])}
                    ]
                })

    # 3. æ³¨å…¥å…¨å±€ç»Ÿè®¡
    ai_pct = round((ai_total_lines / total_lines * 100), 2) if total_lines > 0 else 0
    ai_pct_str = str(ai_pct) + "%"
    props = [
        {"name": "ai:platform", "value": "Ionic-Universal-Flow"},
        {"name": "stats:project:src_total_lines", "value": str(total_lines)},
        {"name": "stats:project:ai_total_lines", "value": str(ai_total_lines)},
        {"name": "stats:project:ai_whole_file_lines", "value": str(ai_whole_lines)},
        {"name": "stats:project:ai_partial_lines", "value": str(ai_partial_lines)},
        {"name": "stats:project:ai_percentage", "value": ai_pct_str},
        {"name": "stats:project:whole_files_count", "value": str(whole_files_count)},
        {"name": "stats:project:partial_files_count", "value": str(partial_files_count)},
        {"name": "stats:project:src_files_scanned", "value": str(len(src_files))},
        {"name": "stats:src_total_lines", "value": str(total_lines)},
        {"name": "stats:ai_total_lines", "value": str(ai_total_lines)},
        {"name": "stats:ai_percentage", "value": ai_pct_str},
        {"name": "build:scan_time", "value": datetime.now().isoformat()},
    ]
    if commit_stats is not None:
        props.extend([
            {"name": "git:commit", "value": git_commit or "unknown"},
            {"name": "git:commit_short", "value": git_commit_short or "unknown"},
            {"name": "stats:commit:ai_lines", "value": str(commit_stats["ai_lines"])},
            {"name": "stats:commit:total_added", "value": str(commit_stats["total_added"])},
            {"name": "stats:commit:changed_files", "value": str(commit_stats["changed_files"])},
            {"name": "stats:commit:ai_changed_files", "value": str(commit_stats["ai_changed_files"])},
        ])
        if commit_stats["total_added"] > 0:
            commit_pct = round(commit_stats["ai_lines"] / commit_stats["total_added"] * 100, 2)
            props.append({"name": "stats:commit:ai_percentage", "value": str(commit_pct) + "%"})
    bom["metadata"]["properties"] = props

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(bom, f, indent=2)

    print("ğŸ“Š [é¡¹ç›®ç´¯è®¡] src/ å…¨é‡ç»Ÿè®¡:")
    print("   æ€»è¡Œæ•°: %s | æ‰«ææ–‡ä»¶: %s" % (total_lines, len(src_files)))
    print("   AI è¡Œæ•°: %s (æ•´æ–‡ä»¶ %s + ç‰‡æ®µ %s)" % (ai_total_lines, ai_whole_lines, ai_partial_lines))
    print("   æ¸—é€ç‡: %s%%" % ai_pct)
    print("   æ•´æ–‡ä»¶: %s ä¸ª | éƒ¨åˆ†ç‰‡æ®µ: %s ä¸ª" % (whole_files_count, partial_files_count))
    if commit_stats is not None:
        print("ğŸ“Š [å½“å‰æäº¤] diff ç»Ÿè®¡:")
        print("   å˜æ›´æ–‡ä»¶: %s ä¸ª | å« AI: %s ä¸ª" % (commit_stats["changed_files"], commit_stats["ai_changed_files"]))
        print("   æœ¬ commit æ–°å¢: %s è¡Œ | AI éƒ¨åˆ†: %s è¡Œ" % (commit_stats["total_added"], commit_stats["ai_lines"]))
        if commit_stats["total_added"] > 0:
            cp = round(commit_stats["ai_lines"] / commit_stats["total_added"] * 100, 2)
            print("   æœ¬ commit AI å æ¯”: %s%%" % cp)
    print("âœ… AIBOM å·²ç”Ÿæˆ: %s" % output_path)

    if opts.append_history and os.path.isdir(os.path.join(project_root, ".git")):
        gc = git_commit or _run_git(["git", "rev-parse", "HEAD"], project_root)
        gcs = git_commit_short or _run_git(["git", "rev-parse", "--short", "HEAD"], project_root)
        _append_history(project_root, commit_stats, total_lines, ai_total_lines, gc, gcs)


def _append_history(project_root, commit_stats, proj_total, proj_ai, git_commit, git_commit_short):
    history_path = os.path.join(project_root, "aibom-history.json")
    entry = {
        "timestamp": datetime.now().isoformat(),
        "commit": git_commit or "unknown",
        "commit_short": git_commit_short or "unknown",
        "project_total_lines": proj_total,
        "project_ai_lines": proj_ai,
        "project_ai_percentage": round(proj_ai / proj_total * 100, 2) if proj_total > 0 else 0,
    }
    if commit_stats:
        entry["commit_ai_lines"] = commit_stats["ai_lines"]
        entry["commit_total_added"] = commit_stats["total_added"]
        entry["commit_changed_files"] = commit_stats["changed_files"]
    data = []
    if os.path.exists(history_path):
        try:
            with open(history_path, "r", encoding="utf-8") as f:
                data = json.load(f)
        except Exception:
            pass
    data.append(entry)
    with open(history_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    print("âœ… å†å²å·²è¿½åŠ : %s" % history_path)


def main():
    parser = argparse.ArgumentParser(description="AIBOM å…¨é‡ç»Ÿè®¡ï¼ˆé¡¹ç›®ç´¯è®¡ + å½“å‰æäº¤ï¼‰")
    parser.add_argument("--commit", action="store_true", help="å¯ç”¨å½“å‰æäº¤ diff ç»Ÿè®¡")
    parser.add_argument("--base", default="HEAD~1", help="diff åŸºå‡† refï¼Œé»˜è®¤ HEAD~1")
    parser.add_argument("--append-history", action="store_true", help="è¿½åŠ æœ¬æ¬¡ç»Ÿè®¡åˆ° aibom-history.json")
    args = parser.parse_args()
    process(args)


if __name__ == "__main__":
    main()
