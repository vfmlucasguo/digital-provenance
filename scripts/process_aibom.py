"""
AIBOM å…¨é‡ç»Ÿè®¡è„šæœ¬ï¼šæ”¯æŒæ•´æ–‡ä»¶ + éƒ¨åˆ†ä»£ç ç‰‡æ®µ

## æ”¯æŒçš„æ ‡æ³¨æ–¹å¼

1. **æ•´æ–‡ä»¶ - è·¯å¾„**: è·¯å¾„å« `ai-gen` â†’ æ•´ä¸ªæ–‡ä»¶è®¡ä¸º AI
2. **æ•´æ–‡ä»¶ - å¤´éƒ¨**: å‰ 10 è¡Œå†…ä»»ä¸€è¡Œå« `@ai-generated` æˆ– `@generated-ai` â†’ æ•´ä¸ªæ–‡ä»¶
3. **éƒ¨åˆ† - å—å¼€å§‹/ç»“æŸ**:
   - `// @ai-generated-begin` ... `// @ai-generated-end` ä¹‹é—´çš„è¡Œ
4. **éƒ¨åˆ† - ç‹¬ç«‹æ³¨é‡Šå—**: `// @ai-generated` å•ç‹¬ä¸€è¡Œ â†’ æ ‡è®°ä¸‹ä¸€å—ï¼ˆåˆ°ç¼©è¿›å›é€€ï¼‰
5. **éƒ¨åˆ† - è¡Œå°¾/è¡Œå†…**: æŸè¡Œå« `@ai-generated` â†’ è¯¥è¡Œè®¡ä¸º AI

## æ”¯æŒæ–‡ä»¶ç±»å‹
.ts, .tsx, .html, .htm, .scss, .css, .js, .jsx, .vue
"""
import json
import os
from datetime import datetime
from pathlib import Path

# æ”¯æŒçš„æ–‡ä»¶ç±»å‹
SRC_EXTENSIONS = ('.ts', '.tsx', '.html', '.htm', '.scss', '.css', '.js', '.jsx', '.vue')
# å¤´éƒ¨åˆ¤å®šè¡Œæ•°
HEADER_LINES = 10
# AI æ ‡è®°å…³é”®å­—ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
AI_MARKERS = ('@ai-generated', '@ai-generated-begin', '@ai-generated-end', '@generated-ai')


def _get_base_indent(line: str) -> int:
    return len(line) - len(line.lstrip())


def _count_non_empty(lines: list[str]) -> int:
    return sum(1 for l in lines if l.strip())


def analyze_file(file_path: str, project_root: str = ".") -> dict:
    """
    åˆ†æå•ä¸ªæ–‡ä»¶ï¼Œè¿”å›æ•´æ–‡ä»¶/éƒ¨åˆ†ç‰‡æ®µçš„ AI ç»Ÿè®¡
    æ”¯æŒ: è·¯å¾„(ai-gen)ã€å¤´éƒ¨(@ai-generated)ã€è¡Œå°¾ã€å—(@ai-generated-begin/end)
    """
    full_path = os.path.join(project_root, file_path)
    result = {
        "total_lines": 0,
        "whole_file": False,
        "partial_lines": 0,
        "ai_lines": 0,
        "scope": "none",
        "details": []
    }
    try:
        with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
    except Exception:
        return result

    total = _count_non_empty(lines)
    result["total_lines"] = total
    if total == 0:
        return result

    # 1. æ•´æ–‡ä»¶ï¼šè·¯å¾„å« ai-gen
    if 'ai-gen' in file_path.lower():
        result["whole_file"] = True
        result["ai_lines"] = total
        result["scope"] = "whole"
        return result

    # 2. æ•´æ–‡ä»¶ï¼šå¤´éƒ¨(å‰ N è¡Œ) æœ‰ @ai-generated æˆ– @generated-ai
    for line in lines[:HEADER_LINES]:
        sl = line.strip().lower()
        if '@ai-generated' in sl or '@generated-ai' in sl:
            if '@ai-generated-end' not in sl:
                result["whole_file"] = True
                result["ai_lines"] = total
                result["scope"] = "whole"
                return result

    # 3. éƒ¨åˆ†ç‰‡æ®µï¼šè¡Œçº§ + å—çº§æ ‡è®°
    ai_line_indices = set()
    in_block = False
    block_indent = -1

    i = 0
    while i < len(lines):
        line = lines[i]
        stripped = line.strip()
        s_lower = stripped.lower()
        indent = _get_base_indent(line)

        if not stripped:
            i += 1
            continue

        # å—ç»“æŸ
        if '@ai-generated-end' in s_lower:
            in_block = False
            block_indent = -1
            i += 1
            continue

        # å—å¼€å§‹
        if '@ai-generated-begin' in s_lower:
            in_block = True
            block_indent = indent
            i += 1
            continue

        if in_block:
            if indent <= block_indent and block_indent >= 0:
                in_block = False
            else:
                ai_line_indices.add(i)
            i += 1
            continue

        # çº¯æ³¨é‡Šè¡Œä¸Šçš„ standalone æ ‡è®°ï¼šæ ‡è®°ã€Œä¸‹ä¸€å—ã€åˆ°ç¼©è¿›å›é€€
        is_comment = (
            s_lower.startswith('//') or s_lower.startswith('#') or
            s_lower.startswith('*') or s_lower.startswith('<!--')
        )
        if is_comment and ('@ai-generated' in s_lower or '@generated-ai' in s_lower):
            if '@ai-generated-end' in s_lower or '@ai-generated-begin' in s_lower:
                i += 1
                continue
            # æ ‡è®°ä¸‹ä¸€å—ï¼šä»ä¸‹ä¸€éç©ºè¡Œèµ·ï¼Œç›´åˆ°ç¼©è¿›ä¸¥æ ¼å°äºæ³¨é‡Šè¡Œ
            j = i + 1
            while j < len(lines):
                nl = lines[j]
                ns = nl.strip()
                ni = _get_base_indent(lines[j])
                if not ns:
                    j += 1
                    continue
                if ni < indent:
                    break
                if '@ai-generated' in ns.lower() or '@ai-generated-begin' in ns.lower():
                    break
                ai_line_indices.add(j)
                j += 1
            i += 1
            continue

        # è¡Œå°¾/è¡Œå†…æ ‡è®°ï¼šè¯¥è¡Œå« @ai-generated
        if ('@ai-generated' in s_lower or '@generated-ai' in s_lower) and '@ai-generated-end' not in s_lower:
            ai_line_indices.add(i)

        i += 1

    result["partial_lines"] = len(ai_line_indices)
    result["ai_lines"] = len(ai_line_indices)
    if result["ai_lines"] > 0:
        result["scope"] = "partial"
    return result


def collect_src_files(project_root: str, src_dir: str = "src") -> list[str]:
    """é€’å½’æ”¶é›† src ä¸‹æ‰€æœ‰æ”¯æŒçš„æºæ–‡ä»¶"""
    base = os.path.join(project_root, src_dir)
    if not os.path.isdir(base):
        return []
    files = []
    for root, _, names in os.walk(base):
        for name in names:
            if name.lower().endswith(SRC_EXTENSIONS):
                full = os.path.join(root, name)
                rel = os.path.relpath(full, project_root)
                files.append(rel.replace("\\", "/"))
    return sorted(files)


def process():
    input_path = "base-sbom.json"
    output_path = "aibom-final.json"
    project_root = "."

    # 1. ç›´æ¥æ‰«æ src/ è·å–å…¨é‡æ–‡ä»¶ï¼ˆä¸ä¾èµ– BOMï¼‰
    src_files = collect_src_files(project_root)
    file_results = {}
    total_lines = 0
    ai_whole_lines = 0
    ai_partial_lines = 0
    whole_files_count = 0
    partial_files_count = 0

    for fp in src_files:
        r = analyze_file(fp, project_root)
        file_results[fp] = r
        total_lines += r["total_lines"]
        if r["scope"] == "whole":
            ai_whole_lines += r["ai_lines"]
            whole_files_count += 1
        elif r["scope"] == "partial":
            ai_partial_lines += r["partial_lines"]
            partial_files_count += 1

    ai_total_lines = ai_whole_lines + ai_partial_lines

    # 2. åŠ è½½ BOM å¹¶æ›´æ–°åŒ¹é…çš„ç»„ä»¶
    bom = {"metadata": {"properties": []}, "components": []}
    if os.path.exists(input_path):
        with open(input_path, 'r', encoding='utf-8') as f:
            bom = json.load(f)

    def set_prop(props: list, name: str, value: str):
        for p in props:
            if p.get("name") == name:
                p["value"] = value
                return
        props.append({"name": name, "value": value})

    for fp, r in file_results.items():
        if r["scope"] in ("whole", "partial"):
            matched = False
            for comp in bom.get("components", []):
                cname = comp.get("name", "")
                if fp in cname or cname.endswith(fp) or os.path.normpath(fp) in os.path.normpath(cname):
                    props = comp.setdefault("properties", [])
                    set_prop(props, "ai:generated", "true")
                    set_prop(props, "ai:scope", r["scope"])
                    set_prop(props, "ai:lines", str(r["ai_lines"]))
                    matched = True
            if not matched and bom.get("components") is not None:
                # BOM ä¸­å¯èƒ½æ— è¯¥æ–‡ä»¶ï¼Œæ³¨å…¥ä¸º file ç»„ä»¶
                bom["components"].append({
                    "type": "file",
                    "name": fp,
                    "properties": [
                        {"name": "ai:generated", "value": "true"},
                        {"name": "ai:scope", "value": r["scope"]},
                        {"name": "ai:lines", "value": str(r["ai_lines"])}
                    ]
                })

    # 3. æ³¨å…¥å…¨å±€ç»Ÿè®¡
    ai_pct = round((ai_total_lines / total_lines * 100), 2) if total_lines > 0 else 0
    bom["metadata"]["properties"] = [
        {"name": "ai:platform", "value": "Ionic-Universal-Flow"},
        {"name": "stats:src_total_lines", "value": str(total_lines)},
        {"name": "stats:ai_total_lines", "value": str(ai_total_lines)},
        {"name": "stats:ai_whole_file_lines", "value": str(ai_whole_lines)},
        {"name": "stats:ai_partial_lines", "value": str(ai_partial_lines)},
        {"name": "stats:ai_percentage", "value": f"{ai_pct}%"},
        {"name": "stats:whole_files_count", "value": str(whole_files_count)},
        {"name": "stats:partial_files_count", "value": str(partial_files_count)},
        {"name": "stats:src_files_scanned", "value": str(len(src_files))},
        {"name": "build:scan_time", "value": datetime.now().isoformat()}
    ]

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(bom, f, indent=2)

    print(f"ğŸ“Š [src/] å…¨é‡ç»Ÿè®¡:")
    print(f"   æ€»è¡Œæ•°: {total_lines} | æ‰«ææ–‡ä»¶: {len(src_files)}")
    print(f"   AI è¡Œæ•°: {ai_total_lines} (æ•´æ–‡ä»¶ {ai_whole_lines} + ç‰‡æ®µ {ai_partial_lines})")
    print(f"   æ¸—é€ç‡: {ai_pct}%")
    print(f"   æ•´æ–‡ä»¶: {whole_files_count} ä¸ª | éƒ¨åˆ†ç‰‡æ®µ: {partial_files_count} ä¸ª")
    print(f"âœ… AIBOM å·²ç”Ÿæˆ: {output_path}")


if __name__ == "__main__":
    process()
